import sys
from fastapi import FastAPI, HTTPException, UploadFile, File
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
from transformers import pipeline
from PIL import Image
import io
import uvicorn


# H√†m log c∆∞·ª°ng √©p in ra m√†n h√¨nh Docker ngay l·∫≠p t·ª©c
def force_log(message):
    print(message, flush=True)


app = FastAPI()

force_log("‚è≥ ƒêang kh·ªüi ƒë·ªông AI Service...")

# --- 1. MODEL TEXT (Vector 768 dimensions) ---
# L∆∞u √Ω: Model n√†y tr·∫£ v·ªÅ vector 768 chi·ªÅu.
force_log("‚è≥ 1/3: Loading Text Embedding Model...")
embed_model = SentenceTransformer('VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')

force_log("‚è≥ 2/3: Loading Text Toxicity Model...")
moderation_pipeline = pipeline("text-classification", model="tarudesu/ViSoBERT-HSD")

# --- 2. MODEL ·∫¢NH (D√πng Google ViT chu·∫©n) ---
# Model n√†y nh·∫≠n di·ªán v·∫≠t th·ªÉ c·ª±c t·ªët: dao, s√∫ng, m√°u, xe tƒÉng...
force_log("‚è≥ 3/3: Loading Image Detection Model (Google ViT)...")
object_pipeline = pipeline("image-classification", model="google/vit-base-patch16-224")

force_log("‚úÖ AI SERVICE ƒê√É S·∫¥N S√ÄNG NH·∫¨N REQUEST!")

# Danh s√°ch mapping t·ª´ nh√£n ti·∫øng Anh (ImageNet) sang c·∫£nh b√°o ti·∫øng Vi·ªát
DANGEROUS_OBJECTS = {
    # Nh√≥m dao/ki·∫øm
    "cleaver": "Dao phay/Dao b·∫ßu",
    "letter opener": "Dao r·ªçc gi·∫•y/V·∫≠t s·∫Øc nh·ªçn",
    "knife": "Dao",
    "switchblade": "Dao b·∫•m",
    "hatchet": "R√¨u tay",
    "axe": "R√¨u",
    "sword": "Ki·∫øm",
    "dagger": "Dao gƒÉm",

    # Nh√≥m s√∫ng ƒë·∫°n
    "revolver": "S√∫ng l·ª•c",
    "assault rifle": "S√∫ng tr∆∞·ªùng t·∫•n c√¥ng",
    "rifle": "S√∫ng tr∆∞·ªùng",
    "shotgun": "S√∫ng sƒÉn",
    "holster": "Bao s√∫ng (nghi v·∫•n v≈© kh√≠)",
    "tank": "Xe tƒÉng/V≈© kh√≠ qu√¢n s·ª±",
    "projectile": "ƒê·∫°n d∆∞·ª£c",

    # Nh√≥m kh√°c
    "syringe": "Kim ti√™m",
    "guillotine": "M√°y ch√©m"
}


class TextRequest(BaseModel):
    text: str


@app.get("/")
def health_check():
    return {"status": "AI Service Running - Model: Google ViT"}


@app.post("/embed")
def create_embedding(request: TextRequest):
    try:
        # force_log(f"üîç Embedding text: {request.text[:20]}...")
        embedding = embed_model.encode(request.text)
        return {"vector": embedding.tolist(), "dimension": len(embedding)}
    except Exception as e:
        force_log(f"‚ùå Embed Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/moderate")
def moderate_text(request: TextRequest):
    # (Code gi·ªØ nguy√™n, ch·ªâ th√™m log n·∫øu c·∫ßn)
    return {"is_toxic": False, "reason": "Clean"}


@app.post("/moderate/image")
def moderate_image(file: UploadFile = File(...)):
    try:
        force_log(f"\n--- üì∏ NH·∫¨N ƒê∆Ø·ª¢C ·∫¢NH: {file.filename} ---")

        image_data = file.file.read()
        image = Image.open(io.BytesIO(image_data))

        # G·ªçi Google ViT ƒë·ªÉ nh·∫≠n di·ªán (l·∫•y Top 5 kh·∫£ nƒÉng cao nh·∫•t)
        results = object_pipeline(image, top_k=5)

        # In log chi ti·∫øt ra terminal ƒë·ªÉ b·∫°n xem n√≥ nh√¨n th·∫•y g√¨
        force_log("üëâ K·∫æT QU·∫¢ QU√âT (Top 5):")
        for idx, res in enumerate(results):
            label_en = res['label'].lower()
            score = res['score']
            force_log(f"   [{idx + 1}] Label: '{label_en}' - Score: {round(score * 100, 1)}%")

        # Logic ch·∫∑n
        for res in results:
            label_en = res['label'].lower()
            score = res['score']

            # Check xem label c√≥ ch·ª©a t·ª´ kh√≥a nguy hi·ªÉm kh√¥ng
            # V√≠ d·ª•: label l√† "meat cleaver" ch·ª©a t·ª´ "cleaver" -> Ch·∫∑n
            for danger_key, vi_msg in DANGEROUS_OBJECTS.items():
                if danger_key in label_en and score > 0.4:  # ƒê·ªô tin c·∫≠y > 40% l√† ch·∫∑n
                    log_msg = f"‚ùå PH√ÅT HI·ªÜN VI PH·∫†M: {label_en} -> {vi_msg}"
                    force_log(log_msg)
                    return {
                        "is_toxic": True,
                        "reason": f"V·∫≠t nguy hi·ªÉm: {vi_msg} ({round(score * 100, 1)}%)",
                        "label": label_en,
                        "score": score
                    }

        force_log("‚úÖ ·∫¢NH AN TO√ÄN")
        return {
            "is_toxic": False,
            "reason": "Clean",
            "label": results[0]['label'],
            "score": results[0]['score']
        }

    except Exception as e:
        force_log(f"‚ùå L·ªñI X·ª¨ L√ù ·∫¢NH: {e}")
        return {"is_toxic": False, "error": str(e)}


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=5000)